{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "617771f6-eeb1-49e9-923c-f7f570c3659a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile train.py\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Read everything from the single “train” channel\n",
    "    train_dir = \"/opt/ml/input/data/train\"\n",
    "    X = pd.read_parquet(os.path.join(train_dir, \"X_train.parquet\"))\n",
    "    y = pd.read_parquet(os.path.join(train_dir, \"y_train.parquet\")).squeeze()\n",
    "\n",
    "    # 2) Log‑transform target\n",
    "    y = np.log1p(y)\n",
    "\n",
    "    # 3) Split out your own validation set\n",
    "    X_tr, X_val, y_tr, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # 4) Wrap in DMatrix\n",
    "    dtrain = xgb.DMatrix(X_tr, label=y_tr)\n",
    "    dvalid = xgb.DMatrix(X_val, label=y_val)\n",
    "\n",
    "    # 5) Parse hyperparameters\n",
    "    import argparse\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--objective\",            type=str,   default=\"reg:squarederror\")\n",
    "    parser.add_argument(\"--max_depth\",            type=int,   default=6)\n",
    "    parser.add_argument(\"--eta\",                  type=float, default=0.1)\n",
    "    parser.add_argument(\"--subsample\",            type=float, default=0.8)\n",
    "    parser.add_argument(\"--colsample_bytree\",     type=float, default=0.8)\n",
    "    parser.add_argument(\"--num_round\",            type=int,   default=100)\n",
    "    parser.add_argument(\"--early_stopping_rounds\",type=int,   default=25)\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    params = {\n",
    "        \"objective\":        args.objective,\n",
    "        \"max_depth\":        args.max_depth,\n",
    "        \"eta\":              args.eta,\n",
    "        \"subsample\":        args.subsample,\n",
    "        \"colsample_bytree\": args.colsample_bytree,\n",
    "    }\n",
    "\n",
    "    # 6) Train with validation\n",
    "    model = xgb.train(\n",
    "        params,\n",
    "        dtrain,\n",
    "        num_boost_round=args.num_round,\n",
    "        evals=[(dtrain, \"train\"), (dvalid, \"validation\")],\n",
    "        early_stopping_rounds=args.early_stopping_rounds,\n",
    "        verbose_eval=50,\n",
    "    )\n",
    "\n",
    "    # 7) Save model for SageMaker\n",
    "    model_dir = os.environ[\"SM_MODEL_DIR\"]\n",
    "    model.save_model(os.path.join(model_dir, \"model.bst\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
